# 프로젝트 현재 상태 보고서

**문서 갱신 시각: 2026-02-10 00:27:02 KST**
**기준 경로: `/mnt/c/Users/USER/growit-pipeline`**

이 문서는 코드, 로그, 데이터 파일 스냅샷 기준으로 현재 상태를 상세 기록한 문서입니다.

## 1. 저장소 상태

- 브랜치: `main`
- HEAD: `86dd227` (`UI upgrade2`)
- 최근 커밋
- `86dd227` UI upgrade2
- `89cf977` UI upgrade
- `8fde567` vercel 배포준비 1
- `3f8139f` 커리큘럼 변경

작업 트리는 dirty 상태입니다.

- 수정 파일(12개)
- `daily-spark-learn-main/daily-spark-learn-main/src/App.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/components/DayCard.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/components/Header.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/components/Hero.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/components/HowItWorks.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/components/MissionDashboard.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/lib/curriculum.ts`
- `daily-spark-learn-main/daily-spark-learn-main/src/lib/missionContent.ts`
- `daily-spark-learn-main/daily-spark-learn-main/src/pages/Curriculum.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/pages/Index.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/pages/Learn.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/tailwind.config.ts`
- 미추적 파일(5개)
- `daily-spark-learn-main/daily-spark-learn-main/CONTENT_GUIDE.md`
- `daily-spark-learn-main/daily-spark-learn-main/src/components/CourseSelectionModal.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/components/LanguageToggle.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/contexts/LanguageContext.tsx`
- `daily-spark-learn-main/daily-spark-learn-main/src/lib/translations.ts`
- 변경량 요약: 12 files changed, 825 insertions(+), 647 deletions(-)

## 2. 파이프라인 구현 상태

구현 경로 및 책임은 아래와 같습니다.

- API 수집: `web/app.py`
- `POST /api/events` 수집
- `data/bronze/app/YYYY/MM/DD/part-YYYYMMDD-HH.jsonl` 기록
- `USE_MINIO=true`일 때 MinIO 업로드 수행
- 오케스트레이션: `airflow/dags/growit_etl.py`
- DAG `growit_etl` 매시 정각 스케줄 (`0 * * * *`)
- `check_bronze`가 입력 파일 존재 시에만 `spark_etl` 실행
- ETL: `spark/app/job_etl.py`
- Bronze JSON -> `event_date` 추가 -> `event_id` 기준 중복 제거 -> Delta append
- 인프라 정의: `docker-compose.yml`
- `web`, `minio`, `spark-master`, `spark-worker`, `spark-history`, `airflow` 포함

## 3. 환경설정 스냅샷 (.env)

현재 확인된 주요 토글은 아래와 같습니다.

- `AUTH_MODE=off`
- `USE_MINIO=false`
- `CORS_ORIGINS=https://growit-pipeline.vercel.app,http://localhost:3000,http://127.0.0.1:3000`
- `WEB_PORT=3000`
- `AIRFLOW_PORT=8082`
- `MINIO_API_PORT=9000`
- `MINIO_CONSOLE_PORT=9001`
- `SPARK_UI_PORT=18080`
- `SPARK_HISTORY_PORT=18081`

## 4. 데이터 레이어 상태

### 4.1 Bronze (`data/bronze/app`)

- 파일 수(`part-*.jsonl`): 4
- 전체 이벤트 라인 수: 15
- 파일별 라인 수
- `data/bronze/app/2026/01/28/part-20260128-14.jsonl`: 1
- `data/bronze/app/2026/02/01/part-20260201-12.jsonl`: 10
- `data/bronze/app/2026/02/04/part-20260204-12.jsonl`: 3
- `data/bronze/app/2026/02/05/part-20260205-14.jsonl`: 1
- 최근 파일 수정 시각: `2026-02-05 23:35:17` (`part-20260205-14.jsonl`)

### 4.2 Delta (`data/delta/events`)

- `_delta_log` JSON 버전 파일 수: 13 (`000...000.json` ~ `000...012.json`)
- 누적 `numOutputRows` 합계: 130
- 파티션: `event_date=2026-02-01` 확인
- 디스크 사용량: `104K` (`data/delta/events`)

## 5. Airflow/Spark 로그 상태

로그 파일 기준으로 확인된 상태는 아래와 같습니다.

- `check_bronze` task 로그 파일 수: 106
- 로그에서 확인된 조건 결과
- `Condition result is True`: 15회
- `Condition result is False`: 85회
- `spark_etl` task 로그 파일 수: 15
- `spark_etl` 로그 내 결과
- `Marking task as SUCCESS`: 13회
- `Task failed with exception`: 2회

실패 기록(과거)

- `manual__2026-01-28T14:04:10...` 및 `manual__2026-01-28T14:10:10...`
- 오류: `Could not parse Master URL: 'spark-master:7077'`

주의 로그(성공으로 마킹됐지만 경고/오류 존재)

- `scheduled__2026-02-01T21:00:00+00:00`의 `spark_etl` 로그에서 Delta checkpoint temp 파일 `Permission denied` 경고/오류가 연속 발생
- 동일 로그 말미에 task가 SUCCESS로 마킹된 이력 존재
- 해석: Airflow task 상태와 Spark 내부 경고가 완전히 일치하지 않을 수 있음

## 6. 프론트엔드 연동 상태

- UI 경로: `daily-spark-learn-main/daily-spark-learn-main`
- 코드 검색 기준(`src`): `/api/events`, `sendEvent`, `API_URL` 패턴 미검출
- 결론: 현재 UI에는 백엔드 이벤트 전송 로직이 포함되지 않은 상태로 판단됨

## 7. 용량/로그 규모

- `data/bronze`: `8.0K`
- `data/delta/events`: `104K`
- `airflow/logs`: `48M`
- `tmp`: `9.0M`

## 8. 현재 리스크 및 미완료 항목

- `spark_etl` 일부 실행에서 Spark 내부 오류가 있었으나 Airflow는 SUCCESS 처리된 이력 존재
- Delta 파티션이 현재 `event_date=2026-02-01` 중심으로 형성되어 있으며 Bronze 날짜 범위와 완전 일치하지 않을 가능성 존재
- UI에서 이벤트 수집 API 호출 코드가 아직 연결되지 않음
- 작업 트리 dirty 상태이므로 배포/커밋 전 변경 의도 검증 필요

## 9. 참고 문서/파일

- 운영/구성 설명: `PROJECT_MANUAL.md`
- 인프라 정의: `docker-compose.yml`
- API 서버: `web/app.py`
- Airflow DAG: `airflow/dags/growit_etl.py`
- Spark ETL: `spark/app/job_etl.py`
