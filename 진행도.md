# 프로젝트 현재 상태 보고서

**문서 갱신 시각: 2026-02-11 01:49:17 KST**
**기준 경로: `/mnt/c/Users/USER/growit-pipeline`**

이 문서는 코드, 로그, 데이터 파일 스냅샷 기준으로 현재 상태를 상세 기록한 문서입니다.

## 1. 저장소 상태

- 브랜치: `main`
- HEAD: `c4276a3` (`app수정`)
- 최근 커밋
- `c4276a3` app수정
- `4f8fdc1` 이벤트 전역 추가
- `0316608` env 수정
- `a78e0dd` env

작업 트리는 dirty 상태입니다.

- 수정 파일(3개)
- `spark/app/job_etl.py`
- `web/app.py`
- `진행도.md`

## 2. 파이프라인 구현 상태

구현 경로 및 책임은 아래와 같습니다.

- API 수집: `web/app.py`
- `POST /api/events` 수집
- `data/bronze/app/YYYY/MM/DD/part-YYYYMMDD-HH.jsonl` 기록
- `USE_MINIO=true`일 때 MinIO 업로드 수행
- 오케스트레이션: `airflow/dags/growit_etl.py`
- DAG `growit_etl` 매시 정각 스케줄 (`0 * * * *`)
- `check_bronze`가 입력 파일 존재 시에만 `spark_etl` 실행
- ETL: `spark/app/job_etl.py`
- Bronze JSON -> 고정 스키마 정규화(`event_version`, `metadata_json`) -> `event_date` 추가 -> `event_id` 기준 중복 제거 -> Delta append
- 하위 호환: 구 포맷의 `metadata` struct는 `to_json(metadata)`로 변환하여 `metadata_json`에 적재
- Delta 쓰기 시 `.option("mergeSchema", "true")` 적용(가산 컬럼 마이그레이션 목적)
- 인프라 정의: `docker-compose.yml`
- `web`, `minio`, `spark-master`, `spark-worker`, `spark-history`, `airflow` 포함

## 3. 환경설정 스냅샷 (.env)

현재 확인된 주요 토글은 아래와 같습니다.

- `AUTH_MODE=off`
- `USE_MINIO=false`
- `CORS_ORIGINS=https://daily-spark-learn-u81a.vercel.app,http://localhost:8080,http://127.0.0.1:8080`
- `CORS_ALLOW_ORIGIN_REGEX`는 `.env` 미설정 시 `web/app.py` 기본값 `^https://.*\.vercel\.app$` 적용
- `WEB_PORT=3000`
- `AIRFLOW_PORT=8082`
- `MINIO_API_PORT=9000`
- `MINIO_CONSOLE_PORT=9001`
- `SPARK_UI_PORT=18080`
- `SPARK_HISTORY_PORT=18081`

## 4. 데이터 레이어 상태

### 4.1 Bronze (`data/bronze/app`)

- 파일 수(`part-*.jsonl`): 4
- 전체 이벤트 라인 수: 15
- 파일별 라인 수
- `data/bronze/app/2026/01/28/part-20260128-14.jsonl`: 1
- `data/bronze/app/2026/02/01/part-20260201-12.jsonl`: 10
- `data/bronze/app/2026/02/04/part-20260204-12.jsonl`: 3
- `data/bronze/app/2026/02/05/part-20260205-14.jsonl`: 1
- 최근 파일 수정 시각: `2026-02-05 23:35:17` (`part-20260205-14.jsonl`)

### 4.2 Delta (`data/delta/events`)

- `_delta_log` JSON 버전 파일 수: 13 (`000...000.json` ~ `000...012.json`)
- 누적 `numOutputRows` 합계: 130
- 파티션: `event_date=2026-02-01` 확인
- 디스크 사용량: `104K` (`data/delta/events`)

## 5. Airflow/Spark 로그 상태

로그 파일 기준으로 확인된 상태는 아래와 같습니다.

- `check_bronze` task 로그 파일 수: 106
- 로그에서 확인된 조건 결과
- `Condition result is True`: 15회
- `Condition result is False`: 85회
- `spark_etl` task 로그 파일 수: 15
- `spark_etl` 로그 내 결과
- `Marking task as SUCCESS`: 13회
- `Task failed with exception`: 2회

신규 실패 기록(수집 스키마 확장 이후)

- `manual__2026-02-10T16:33:36.579215+00:00`의 `spark_etl`에서 Delta schema mismatch 발생
- 원인: 기존 Delta 스키마에 `metadata`/`metadata_json` 확장이 반영되지 않은 상태에서 신규 이벤트 payload 유입
- 대응: `web/app.py`를 `metadata_json` 고정 저장으로 전환하고, `spark/app/job_etl.py`에서 고정 스키마 정규화 + `mergeSchema` 적용

실패 기록(과거)

- `manual__2026-01-28T14:04:10...` 및 `manual__2026-01-28T14:10:10...`
- 오류: `Could not parse Master URL: 'spark-master:7077'`

주의 로그(성공으로 마킹됐지만 경고/오류 존재)

- `scheduled__2026-02-01T21:00:00+00:00`의 `spark_etl` 로그에서 Delta checkpoint temp 파일 `Permission denied` 경고/오류가 연속 발생
- 동일 로그 말미에 task가 SUCCESS로 마킹된 이력 존재
- 해석: Airflow task 상태와 Spark 내부 경고가 완전히 일치하지 않을 수 있음

## 6. 프론트엔드 연동 상태

- UI 경로: `daily-spark-learn-main/daily-spark-learn-main`
- 이벤트 전송 클라이언트: `daily-spark-learn-main/daily-spark-learn-main/src/lib/logger.ts`
- API 대상: `VITE_API_URL + /api/events` (`POST`)
- 라우트 이벤트: `daily-spark-learn-main/daily-spark-learn-main/src/App.tsx`의 `RouteChangeTracker`에서 `page_view` 전송
- 전역 UI 이벤트: `daily-spark-learn-main/daily-spark-learn-main/src/App.tsx`의 `GlobalUiEventTracker`에서 `click/change/submit` 캡처 후 전송
- 세부 UI 이벤트: `Hero`, `Header`, `DayCard`, `MissionDashboard`에서 도메인 이벤트 추가 전송
- 수집 payload: `event_version` + `metadata_json` 중심으로 고정 스키마화
- 현재 상태: Vercel -> (ngrok) -> 로컬 FastAPI 경로로 이벤트 적재 연동 완료

## 7. 용량/로그 규모

- `data/bronze`: `8.0K`
- `data/delta/events`: `104K`
- `airflow/logs`: `48M`
- `tmp`: `9.0M`

## 8. 현재 리스크 및 미완료 항목

- `spark_etl` 일부 실행에서 Spark 내부 오류가 있었으나 Airflow는 SUCCESS 처리된 이력 존재
- Delta 파티션이 현재 `event_date=2026-02-01` 중심으로 형성되어 있으며 Bronze 날짜 범위와 완전 일치하지 않을 가능성 존재
- 전역 UI 이벤트 수집으로 이벤트 볼륨이 증가했으므로 분석/비용 관점에서 샘플링 또는 이벤트 화이트리스트 검토 필요
- Vercel preview 도메인/커스텀 도메인 사용 시 CORS 허용 목록(`CORS_ORIGINS`, `CORS_ALLOW_ORIGIN_REGEX`) 점검 필요
- 장기 운영 권장: Silver 레이어에서 이벤트 타입별 정규화 테이블 분리(현재는 Bronze/Delta 단일 적재 중심)

## 9. 참고 문서/파일

- 운영/구성 설명: `PROJECT_MANUAL.md`
- 인프라 정의: `docker-compose.yml`
- API 서버: `web/app.py`
- Airflow DAG: `airflow/dags/growit_etl.py`
- Spark ETL: `spark/app/job_etl.py`
- 프론트 이벤트 클라이언트: `daily-spark-learn-main/daily-spark-learn-main/src/lib/logger.ts`
- 프론트 전역 이벤트 추적: `daily-spark-learn-main/daily-spark-learn-main/src/App.tsx`
